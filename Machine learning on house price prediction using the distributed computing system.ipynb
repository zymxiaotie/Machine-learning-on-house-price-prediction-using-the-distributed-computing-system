{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning on house price prediction using the distributed computing system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how install and integrate pyspark with jupyter:\n",
    "# https://www.dataquest.io/blog/pyspark-installation-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName = \"HousePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read in data from hadoop cluster.\n",
    "df = spark.read.option('header', 'true').option('inferSchema', 'true').csv('hdfs://lena-master:8020/user/zyanm001/Mel_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Rooms: integer (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- SellerG: string (nullable = true)\n",
      " |-- Distance: double (nullable = true)\n",
      " |-- Bedroom2: double (nullable = true)\n",
      " |-- Bathroom: double (nullable = true)\n",
      " |-- Car: double (nullable = true)\n",
      " |-- Landsize: double (nullable = true)\n",
      " |-- Lattitude: double (nullable = true)\n",
      " |-- Longtitude: double (nullable = true)\n",
      " |-- Propertycount: double (nullable = true)\n",
      " |-- log_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24989, 13)\n"
     ]
    }
   ],
   "source": [
    "#sparkDF.count() is an action that returns the number of rows in a DataFrame and \n",
    "# sparkDF.columns returns all columns in a list, python len() function returns the length of the list.\n",
    "\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>14.207553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  Rooms      Price SellerG  Distance  Bedroom2  Bathroom  Car  Landsize  \\\n",
       "0    1      2  1480000.0  Biggin       2.5       2.0       1.0  1.0     202.0   \n",
       "\n",
       "   Lattitude  Longtitude  Propertycount  log_price  \n",
       "0   -37.7996    144.9984         4019.0  14.207553  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = df.randomSplit([0.7, 0.3], seed=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17501, 13)\n",
      "(7488, 13)\n"
     ]
    }
   ],
   "source": [
    "print((trainData.count(), len(trainData.columns)))\n",
    "print((testData.count(), len(testData.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation via VectorAssembler and StringIndexer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StringIndexer transform string column 'SellerG' to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndex = StringIndexer(inputCol='SellerG', outputCol='SellerG_Indexed', handleInvalid='skip' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+-------+--------+--------+--------+---+--------+---------+----------+-------------+------------------+---------------+\n",
      "|_c0|Rooms|    Price|SellerG|Distance|Bedroom2|Bathroom|Car|Landsize|Lattitude|Longtitude|Propertycount|         log_price|SellerG_Indexed|\n",
      "+---+-----+---------+-------+--------+--------+--------+---+--------+---------+----------+-------------+------------------+---------------+\n",
      "|  1|    2|1480000.0| Biggin|     2.5|     2.0|     1.0|1.0|   202.0| -37.7996|  144.9984|       4019.0|14.207552645740298|            9.0|\n",
      "+---+-----+---------+-------+--------+--------+--------+---+--------+---------+----------+-------------+------------------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = stringIndex.fit(trainData).transform(trainData)\n",
    "df1.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorise features with Vector Assimbler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Rooms', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize',\\\n",
    "                                       'Lattitude', 'Longtitude', 'Propertycount', 'SellerG_Indexed'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+-------+--------+--------+--------+---+--------+---------+----------+-------------+------------------+---------------+--------------------+\n",
      "|_c0|Rooms|    Price|SellerG|Distance|Bedroom2|Bathroom|Car|Landsize|Lattitude|Longtitude|Propertycount|         log_price|SellerG_Indexed|            features|\n",
      "+---+-----+---------+-------+--------+--------+--------+---+--------+---------+----------+-------------+------------------+---------------+--------------------+\n",
      "|  1|    2|1480000.0| Biggin|     2.5|     2.0|     1.0|1.0|   202.0| -37.7996|  144.9984|       4019.0|14.207552645740298|            9.0|[2.0,2.5,2.0,1.0,...|\n",
      "+---+-----+---------+-------+--------+--------+--------+---+--------+---------+----------+-------------+------------------+---------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = assembler.transform(df1)\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline model to predict target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT SellerG)|\n",
      "+-----------------------+\n",
      "|                    337|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct('SellerG')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter 'maxBins' should not be smaller than discretization of Categorical features. Hence, we will set 'maxBins' to 337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(labelCol = \"log_price\", maxBins=337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for pipeline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we decide the optimum number of trees and maximum tree depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the estimator as rf\n",
    "\n",
    "# Define the evaluator: \n",
    "evaluator = RegressionEvaluator(labelCol=\"log_price\", predictionCol=\"prediction\", metricName='rmse')\n",
    "\n",
    "# Specify hyperparameters : \n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(rf.maxDepth, [2, 4, 6, 10])\\\n",
    "            .addGrid(rf.numTrees, [10, 50, 100])\\\n",
    "            .build())\n",
    "\n",
    "# Use the CrossValidator to perform cross-validation, evaluating each of the various models\n",
    "cv = CrossValidator(estimator=rf,\\\n",
    "                   evaluator=evaluator,\\\n",
    "                   estimatorParamMaps=paramGrid,\\\n",
    "                   numFolds=5,\\\n",
    "                   seed=42)\n",
    "\n",
    "# build the pipeline\n",
    "cvPipe = Pipeline(stages=[stringIndex, assembler, cv])\n",
    "\n",
    "# build the pipeline model\n",
    "cvPipeModel = cvPipe.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cvPipeModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  0.40559867991986365),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 50},\n",
       "  0.39787033359321045),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  0.3974159610085296),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 4,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  0.34302904547193064),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 4,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 50},\n",
       "  0.33712417288456187),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 4,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  0.33318012846938366),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 6,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  0.3104185034679417),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 6,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 50},\n",
       "  0.3015203425816917),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 6,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  0.29905075713367363),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  0.27575190274954275),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 50},\n",
       "  0.2664828474650756),\n",
       " ({Param(parent='RandomForestRegressor_bbfcf6f85457', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestRegressor_bbfcf6f85457', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  0.2653063236786454)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results shown when 'maxDepth' was setted to 10 and 'numTrees' was setted to 100, we got the best rmse estimate as 0.265. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building for prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor_bbfcf6f85457"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.setNumTrees(100).setMaxDepth(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(stages=[stringIndex, assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeModel = rf_pipe.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_pipeModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|         log_price|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|[2.0,2.5,2.0,1.0,...|13.849911984681606|13.848156722455006|\n",
      "|[3.0,2.5,3.0,2.0,...|14.197365800433305|14.087477635086342|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('features', 'log_price', 'prediction').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.06776965161455895\n"
     ]
    }
   ],
   "source": [
    "MSE = evaluator.setMetricName('mse').evaluate(predictions)\n",
    "print(f\"MSE is {MSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.2603260486669725\n"
     ]
    }
   ],
   "source": [
    "RMSE = evaluator.setMetricName('rmse').evaluate(predictions)\n",
    "print(f\"RMSE is {RMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_trainData = rf_pipeModel.transform(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.05003718662795921\n"
     ]
    }
   ],
   "source": [
    "MSE_trainData = evaluator.setMetricName('mse').evaluate(predictions_trainData)\n",
    "print(f\"MSE is {MSE_trainData}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.22368993412301594\n"
     ]
    }
   ],
   "source": [
    "RMSE_trainData = evaluator.setMetricName('rmse').evaluate(predictions_trainData)\n",
    "print(f\"RMSE is {RMSE_trainData}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison, the pipeline model performance on training dataset and test dataset are close, which indicates the model correctly learns the pattern  instead of memorising the data(overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimising by eliminating insignificant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = rf_pipeModel.stages[-1]\n",
    "# print(rfModel.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to split on the same feature multiple times in a single decision tree but based on different values. Feature 9 appears frequently in single tree splitings, which can also be interpreted as decisions depending frequently on feature 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SellerG_Indexed</td>\n",
       "      <td>0.310629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rooms</td>\n",
       "      <td>0.226974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Distance</td>\n",
       "      <td>0.125013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lattitude</td>\n",
       "      <td>0.093284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longtitude</td>\n",
       "      <td>0.074430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bedroom2</td>\n",
       "      <td>0.069207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Landsize</td>\n",
       "      <td>0.046613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bathroom</td>\n",
       "      <td>0.026246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Propertycount</td>\n",
       "      <td>0.019504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car</td>\n",
       "      <td>0.008101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "9  SellerG_Indexed    0.310629\n",
       "0            Rooms    0.226974\n",
       "1         Distance    0.125013\n",
       "6        Lattitude    0.093284\n",
       "7       Longtitude    0.074430\n",
       "2         Bedroom2    0.069207\n",
       "5         Landsize    0.046613\n",
       "3         Bathroom    0.026246\n",
       "8    Propertycount    0.019504\n",
       "4              Car    0.008101"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureimp = pd.DataFrame(list(zip(assembler.getInputCols(), rfModel.featureImportances)),\\\n",
    "                          columns=['feature', 'importance'])\n",
    "featureimp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature importance could be extracted as above. Feature 9 scored highest importance, while the feature 'Car' contributes less than 1% of the prediction. We will remove this feature and evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_new = VectorAssembler(inputCols=['Rooms', 'Distance', 'Bedroom2', 'Bathroom', 'Landsize',\\\n",
    "                                       'Lattitude', 'Longtitude', 'Propertycount', 'SellerG_Indexed'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe_new = Pipeline(stages=[stringIndex, assembler_new, rf])\n",
    "rf_pipeModel_new = rf_pipe_new.fit(trainData)\n",
    "predictions_new = rf_pipeModel_new.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.06938094178890876\n"
     ]
    }
   ],
   "source": [
    "MSE_new = evaluator.setMetricName('mse').evaluate(predictions_new)\n",
    "print(f\"MSE is {MSE_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.26340262297271977\n"
     ]
    }
   ],
   "source": [
    "RMSE_new = evaluator.setMetricName('rmse').evaluate(predictions_new)\n",
    "print(f\"RMSE is {RMSE_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new_trainData = rf_pipeModel_new.transform(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.051875714571081984\n"
     ]
    }
   ],
   "source": [
    "MSE_new_trainData = evaluator.setMetricName('mse').evaluate(predictions_new_trainData)\n",
    "print(f\"RMSE is {MSE_new_trainData}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.22776240816052587\n"
     ]
    }
   ],
   "source": [
    "RMSE_new_trainData = evaluator.setMetricName('rmse').evaluate(predictions_new_trainData)\n",
    "print(f\"RMSE is {RMSE_new_trainData}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with previous model, the RMSE has increase slightly in both training dataset and testing dataset. That is reasonable as new model has less feature for prediction. However, new model will consuming less computing resource with little decrease in performance by reducing feature numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price prediction with decision tree regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the estimator,\n",
    "dt = DecisionTreeRegressor(labelCol='log_price', maxBins=337)\n",
    "\n",
    "# Define the evaluator: \n",
    "dt_eval = RegressionEvaluator(labelCol=\"log_price\", predictionCol=\"prediction\", metricName='rmse')\n",
    "\n",
    "# Specify hyperparameters : \n",
    "dtparamGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(dt.maxDepth, [2, 4, 6, 10,15,20])\\\n",
    "            .build())\n",
    "\n",
    "# Use the CrossValidator to perform cross-validation, evaluating each of the various models\n",
    "dtcv = CrossValidator(estimator=dt,\\\n",
    "                   evaluator=dt_eval,\\\n",
    "                   estimatorParamMaps=dtparamGrid,\\\n",
    "                   numFolds=5,\\\n",
    "                   seed=42)\n",
    "\n",
    "# build the pipeline\n",
    "dtcvPipe = Pipeline(stages=[stringIndex, assembler_new, dtcv])\n",
    "\n",
    "# build the pipeline model\n",
    "dtcvPipeModel = dtcvPipe.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvModel = dtcvPipeModel.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({Param(parent='DecisionTreeRegressor_34b796ac5db4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 2},\n",
       "  0.4175162516468495),\n",
       " ({Param(parent='DecisionTreeRegressor_34b796ac5db4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 4},\n",
       "  0.35579910077477717),\n",
       " ({Param(parent='DecisionTreeRegressor_34b796ac5db4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 6},\n",
       "  0.3242670208071366),\n",
       " ({Param(parent='DecisionTreeRegressor_34b796ac5db4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10},\n",
       "  0.30436179951340964),\n",
       " ({Param(parent='DecisionTreeRegressor_34b796ac5db4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 15},\n",
       "  0.322657176916045),\n",
       " ({Param(parent='DecisionTreeRegressor_34b796ac5db4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20},\n",
       "  0.33685406587811706)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dtcvModel.getEstimatorParamMaps(), dtcvModel.avgMetrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the 'maxDepth' was 10, we got the lowest(best) rsme value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor_34b796ac5db4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.setMaxDepth(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtPipe = Pipeline(stages=[stringIndex, assembler_new, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtPipeModel = dtPipe.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtPrediction = dtPipeModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.08580504024492315\n"
     ]
    }
   ],
   "source": [
    "MSE_dtPrediction = dt_eval.setMetricName('mse').evaluate(dtPrediction)\n",
    "print(f\"MSE is {MSE_dtPrediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.29292497374741394\n"
     ]
    }
   ],
   "source": [
    "RMSE_dtPrediction = dt_eval.setMetricName('rmse').evaluate(dtPrediction)\n",
    "print(f\"RMSE is {RMSE_dtPrediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtPrediction_trainData = dtPipeModel.transform(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.052858278048429005\n"
     ]
    }
   ],
   "source": [
    "MSE_dtTrainData = dt_eval.setMetricName('mse').evaluate(dtPrediction_trainData)\n",
    "print(f\"MSE is {MSE_dtTrainData}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.2299092822145922\n"
     ]
    }
   ],
   "source": [
    "RMSE_dtTrainData = dt_eval.setMetricName('rmse').evaluate(dtPrediction_trainData)\n",
    "print(f\"RMSE is {RMSE_dtTrainData}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the rmse of training dataset is lower than testing dataset. However, the difference is not big. The decision tree model have correctly learned the patterns from the data instead of memorising data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, random forest regression model performed better than decision tree regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
